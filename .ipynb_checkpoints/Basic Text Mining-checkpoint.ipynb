{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='right' style='float: right'>2016-08-10<br />David Wehr</div>\n",
    "# Basic Text Mining\n",
    "##### Using Python and Scikit-Learn to perform text classification, using the bag-of-words document model, and a linear SVM classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import re\n",
    "from collections import Counter, namedtuple\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, cross_validation, metrics, naive_bayes, ensemble, tree\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open the SQLite Database\n",
    "This contains all of our data, in a table called \"Reviews\", with columns:<br />\n",
    "Id | ProductId | UserId | ProfileName | HelpfulnessNumerator | HelpfulnessDenominator | Score | Time | Summary | Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "connection = sqlite3.connect('amazon-fine-foods/database_small.sqlite')\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Review datatype\n",
    "This will make the code more readable later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Review = namedtuple('Review', ['id', 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Reviews\n",
    "*positive_reviews* will contain all reviews with 4 or 5 stars<br />\n",
    "*negative_reviews* will contain all reviews with 1 or 2 stars<br />\n",
    "We put them together into *reviews*, and create a list of *labels*, where 1 means postive, and 0 is negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review(id=1, text='I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('SELECT Id, Text from Reviews WHERE Score > 3 LIMIT 10000')\n",
    "positive_reviews = list(map(Review._make, cursor.fetchall()))\n",
    "cursor.execute('SELECT Id, Text from Reviews WHERE Score < 3 LIMIT 10000')\n",
    "negative_reviews = list(map(Review._make, cursor.fetchall()))\n",
    "reviews = positive_reviews + negative_reviews\n",
    "labels = [1]*len(positive_reviews) + [0]*len(negative_reviews)\n",
    "reviews[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into test and train sets\n",
    "This will randomly split our data into $\\frac{1}{4}$ testing, $\\frac{3}{4}$ training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_reviews, test_reviews, train_labels, test_labels = cross_validation.train_test_split(reviews, labels, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-Words Model\n",
    "For classifying reviews, we will be using the bag-of-words model. Essentially, treat each paragraph as a list of words, disregarding their order, punctuation, etc.<br/>\n",
    "This has obvious drawbacks. The order is lost, so the semantics of even simple phrases can get lost. For example, it will treat \"I think this food rocks!\" nearly the same as \"I think this food is rocks...\" Two very different meanings. More complex language features, like sarcasm (\"I'm so happy I spent $40 on 1lb of coffee that tastes like Folgers!\"), don't have a chance of being properly represented. Synonyms are treated as different words, so \"bad\" and \"horrible\" are represented as two completely unrelated words.<br />\n",
    "Despite all these drawbacks, it has proven to be a very successful model for text classification.<br/>\n",
    "This model can be extended in a number of ways, with varying success:\n",
    "* Including collocations (multi-word phrases, like \"pickup truck\")\n",
    "* Normalization (TF-IDF, or length normalization)\n",
    "* Word stemming and lemmatization\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization\n",
    "To faciliate the bag-of-words model, we must first convert a paragraph into a list of words.<br />\n",
    "We could just split by spaces, but we'll go a step and further convert everything to lowercase and strip out special characters and punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    # Strip out these characters\n",
    "    text = re.sub(r'[.:;,!#%()\\'<>]', '', text)\n",
    "    # Replace these characters with spaces\n",
    "    text = re.sub(r'[\\-/\\\\&]', ' ', text)\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello',\n",
       " 'world',\n",
       " 'im',\n",
       " 'a',\n",
       " 'consumer',\n",
       " 'reviewer',\n",
       " 'i',\n",
       " 'like',\n",
       " '30',\n",
       " 'of',\n",
       " 'special',\n",
       " 'characters']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(\"Hello, world! (I'm a consumer/reviewer & I like 30% of special-characters)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Vocabulary\n",
    "Most words appear quite infrequently, and so are not likely to contain much reliable prediction power, but slow down computation time. Let's get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words: 39264\n",
      "Our vocabulary size: 10140\n"
     ]
    }
   ],
   "source": [
    "all_words = itertools.chain.from_iterable(tokenize(review.text) for review in reviews)\n",
    "word_counts = Counter(all_words)\n",
    "our_vocab = [word for word, count in word_counts.most_common() if count >= 5]\n",
    "print(\"Total unique words: {}\".format(len(word_counts)))\n",
    "print(\"Our vocabulary size: {}\".format(len(our_vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log-log distribution of most common words and number of times they appear\n",
    "You can see that common words appear exponentially more often than less-common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25974760c50>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEHCAYAAACp9y31AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nESkwSvwiIgXm/wGGXWk/AHjn8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25972bea198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.loglog([count for word, count in word_counts.most_common()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create feature vectors\n",
    "The scikit-learn library expects inputs to be expressed in a matrix, where each row is a training sample. The row is a vector that describes the sample. In our case, the columns correspond with different words, and the entry is the number of times that word appears.<br />\n",
    "Let's say our vocabulary is [*tasty*, *gross*, *okay*]<br />\n",
    "$$\\begin{bmatrix}\n",
    "    2       & 0 & 1 \\\\\n",
    "    0       & 1 & 1 \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\\\\n",
    "    x_{N1}       & x_{N2} & x_{N3}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "In the above example, sample **1** had the word \"tasty\" appear twice, and the word \"okay\" appear once, while sample **2** just had the word \"gross\" appear once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reviews_to_matrix(reviews, vocabulary):\n",
    "    matrix_dims = (len(reviews), len(vocabulary))\n",
    "    mat = np.zeros(matrix_dims)\n",
    "    index_lookup = {word: i for i, word in enumerate(vocabulary)}\n",
    "    for i, review in enumerate(reviews):\n",
    "        #word_counts = Counter(tokenize(review.text))\n",
    "        for word in tokenize(review.text):\n",
    "            idx = index_lookup.get(word)\n",
    "            if idx is not None: mat[i,idx] += 1\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X = reviews_to_matrix(train_reviews, our_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "#### Support Vector Machine\n",
    "Support vector machines separate the feature space into the two separate classes with a hyperplane.<br/>\n",
    "See this for a more in-depth explanation of how SVMs work, and their theoretical underpinnings: http://web.mit.edu/6.034/wwwbob/svm-notes-long-08.pdf\n",
    "<br/><br/>\n",
    "For our purposes, its good to know that a linear SVM works well for high-dimensional data, such as our word counts (~10,000 dimensions). They work well in terms of both performance and prediction accuracy. For lower-dimensional data, a radial-bias function (RBF) kernel tends to work best for most problems.\n",
    "#### Other classification algorithms\n",
    "We could use any supervised machine learning algorithm here, such as:\n",
    "* Naive Bayes - This has traditionally been used with text classification before the popularity of SVMs\n",
    "* Decision Tree - On high-dimensional data, they will tend to overfit. This can be mitigated by using ensembles of decision trees, such as the AdaBoost algorithm\n",
    "* Logistic Regression\n",
    "* K-Nearest Neighbors\n",
    "* Multi-layer Perceptron (Neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = svm.LinearSVC(C=1)\n",
    "#classifier = naive_bayes.MultinomialNB()\n",
    "#classifier = tree.DecisionTreeClassifier()\n",
    "#classifier = ensemble.AdaBoostClassifier(n_estimators=10)\n",
    "classifier.fit(train_X, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions on test set\n",
    "The test set has not been seen yet by the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X = reviews_to_matrix(test_reviews, our_vocab)\n",
    "test_predictions = classifier.predict(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Performance\n",
    "Accuracy is the ratio of correct predictions to the total number of test samples<br/>\n",
    "Precision is the ratio of correctly predicted positive reviews to the number of predicted positive reviews<br/>\n",
    "Recall is the ratio of correctly predicted positive reviews to the total number of positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7896\n",
      "Precision: 0.7676537585421412\n",
      "Recall: 0.8212835093419983\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(test_labels, test_predictions)\n",
    "precision = metrics.precision_score(test_labels, test_predictions)\n",
    "recall = metrics.recall_score(test_labels, test_predictions)\n",
    "print(\"Accuracy: {}\\nPrecision: {}\\nRecall: {}\".format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Evaluation\n",
    "For SVMs, we can see how influential particular words are, and whether they are positive or negative, based on how they influence the hyperplane. Some other classifier algorithms are able to be evaluated in this manner, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive words:\n",
      "['superb', 'camper', 'lazy', 'neat', 'shattered', 'glad', 'senior', 'houttes', 'yea', 'eco', 'satay', '$400', 'puck', 'refined', 'deliciousbr', 'pricy', 'plockys', 'spike', 'additions', 'smoothest']\n",
      "Negative words:\n",
      "['disgusting', 'disappointing', 'revolting', 'canceled', 'horrible', 'manufacturing', 'yuck', 'sickeningly', 'hopes', 'significantly', 'franks', 'hadnt', 'died', 'awful', 'pekoe', 'atleast', 'dead', 'undrinkable', 'explode', 'awesomebr']\n"
     ]
    }
   ],
   "source": [
    "feature_importances = list(zip(classifier.coef_[0], our_vocab))\n",
    "feature_importances.sort(key=lambda t: t[0])\n",
    "print(\"Positive words:\")\n",
    "print([word for score, word in feature_importances[-20:]])\n",
    "print(\"Negative words:\")\n",
    "print([word for score, word in feature_importances[0:20]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
